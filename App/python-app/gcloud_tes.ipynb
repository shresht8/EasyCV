{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from google.auth import default\n",
    "from google.cloud import storage\n",
    "# Get the credentials object\n",
    "credentials, project = default()\n",
    "\n",
    "# Create a GCS client object\n",
    "# client = storage.Client(credentials=credentials, project=project)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-17T08:30:38.342493500Z",
     "start_time": "2024-02-17T08:30:35.226035900Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "client = storage.Client(credentials=credentials,project='KeyProject')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-17T08:30:42.179493600Z",
     "start_time": "2024-02-17T08:30:42.171493100Z"
    }
   },
   "id": "caec2ba7094ed2fe"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucket not found\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    bucket = client.get_bucket(\"easy-cv-bucket-2\")\n",
    "except Exception as e:\n",
    "    print(\"bucket not found\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-17T09:46:34.692784Z",
     "start_time": "2024-02-17T09:46:33.061966100Z"
    }
   },
   "id": "dae080b444a30c55"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_templates/\n",
      "cv_templates/cv_template_1/\n",
      "cv_templates/cv_template_1/bubblecv.sty\n",
      "cv_templates/cv_template_1/main.tex\n",
      "cv_templates/cv_template_1/resources/avatar.png\n",
      "cv_templates/cv_template_1/resources/contact.png\n",
      "cv_templates/cv_template_1/resources/cv.png\n",
      "cv_templates/cv_template_1/resources/education.png\n",
      "cv_templates/cv_template_1/resources/languages.png\n",
      "cv_templates/cv_template_1/resources/person.png\n",
      "cv_templates/cv_template_1/resources/publications.png\n",
      "cv_templates/cv_template_1/resources/shresht_photo.jpg\n",
      "cv_templates/cv_template_1/resources/skills.png\n",
      "cv_templates/cv_template_1/resources/summary.png\n",
      "cv_templates/cv_template_1/resources/target.png\n",
      "cv_templates/cv_template_1/resources/work.png\n",
      "cv_templates/cv_template_2/\n",
      "cv_templates/cv_template_2/disney.png\n",
      "cv_templates/cv_template_2/jack.jpg\n",
      "cv_templates/cv_template_2/main.tex\n",
      "cv_templates/cv_template_2/medal.jpeg\n",
      "cv_templates/cv_template_2/simplehipstercv.cls\n",
      "cv_templates/cv_template_2/simplehipstercv.sty\n",
      "cv_templates/cv_template_3/\n",
      "cv_templates/cv_template_3/developercv.cls\n",
      "cv_templates/cv_template_3/main.tex\n",
      "user/\n",
      "user/Archana_Shetty/\n",
      "user/Archana_Shetty/user_professional_information.txt\n",
      "user/Shresht_Shetty/\n",
      "user/Shresht_Shetty/user_professional_information.txt\n"
     ]
    }
   ],
   "source": [
    "# List all the objects in the bucket \"easy-cv-bucket\"\n",
    "blobs = client.list_blobs(bucket_or_name=\"easy-cv-bucket\")\n",
    "\n",
    "# Print the names of the objects\n",
    "for blob in blobs:\n",
    "  print(blob.name)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T11:10:13.921518700Z",
     "start_time": "2023-11-16T11:10:12.865440100Z"
    }
   },
   "id": "f38e32c9b6124715"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "bucket = client.get_bucket('easy-cv-bucket')\n",
    "blobs = bucket.list_blobs(prefix='cv_templates/cv_template_1/')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T11:17:49.389909500Z",
     "start_time": "2023-11-16T11:17:49.215423700Z"
    }
   },
   "id": "8bb4b0cbe2a3939e"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bubblecv.sty\n",
      "main.tex\n",
      "resources/avatar.png\n",
      "resources/contact.png\n",
      "resources/cv.png\n",
      "resources/education.png\n",
      "resources/languages.png\n",
      "resources/person.png\n",
      "resources/publications.png\n",
      "resources/shresht_photo.jpg\n",
      "resources/skills.png\n",
      "resources/summary.png\n",
      "resources/target.png\n",
      "resources/work.png\n"
     ]
    }
   ],
   "source": [
    "for blob in blobs:\n",
    "  print(blob.name[len('cv_templates/cv_template_1/'):])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T11:17:50.426213600Z",
     "start_time": "2023-11-16T11:17:50.254698700Z"
    }
   },
   "id": "e004568377cd0502"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import os\n",
    "path1=os.path.join('.\\output', 'resources/work.png').replace(\"/\",\"\\\\\")\n",
    "os.makedirs(os.path.dirname(path1), exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T11:24:41.484713800Z",
     "start_time": "2023-11-16T11:24:41.469713Z"
    }
   },
   "id": "8f31cd9b5d1ea2e"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded cv_templates/cv_template_1/bubblecv.sty to .\\output\\bubblecv.sty\n",
      "Downloaded cv_templates/cv_template_1/main.tex to .\\output\\main.tex\n",
      "Downloaded cv_templates/cv_template_1/resources/avatar.png to .\\output\\resources\\avatar.png\n",
      "Downloaded cv_templates/cv_template_1/resources/contact.png to .\\output\\resources\\contact.png\n",
      "Downloaded cv_templates/cv_template_1/resources/cv.png to .\\output\\resources\\cv.png\n",
      "Downloaded cv_templates/cv_template_1/resources/education.png to .\\output\\resources\\education.png\n",
      "Downloaded cv_templates/cv_template_1/resources/languages.png to .\\output\\resources\\languages.png\n",
      "Downloaded cv_templates/cv_template_1/resources/person.png to .\\output\\resources\\person.png\n",
      "Downloaded cv_templates/cv_template_1/resources/publications.png to .\\output\\resources\\publications.png\n",
      "Downloaded cv_templates/cv_template_1/resources/shresht_photo.jpg to .\\output\\resources\\shresht_photo.jpg\n",
      "Downloaded cv_templates/cv_template_1/resources/skills.png to .\\output\\resources\\skills.png\n",
      "Downloaded cv_templates/cv_template_1/resources/summary.png to .\\output\\resources\\summary.png\n",
      "Downloaded cv_templates/cv_template_1/resources/target.png to .\\output\\resources\\target.png\n",
      "Downloaded cv_templates/cv_template_1/resources/work.png to .\\output\\resources\\work.png\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "import os\n",
    "\n",
    "def download_bucket_folder(bucket_name, source_folder, destination_dir):\n",
    "    \"\"\"Download all files from a specific folder in the GCS bucket to the local directory.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "    # Ensure the source folder path is correctly formatted\n",
    "    if not source_folder.endswith('/'):\n",
    "        source_folder += '/'\n",
    "\n",
    "    blobs = bucket.list_blobs(prefix=source_folder)  # List blobs in the specific folder\n",
    "\n",
    "    for blob in blobs:\n",
    "        # Removing the source folder path from the blob name\n",
    "        relative_path = blob.name[len(source_folder):]\n",
    "        if not relative_path:  # Skip if it's just the folder itself\n",
    "            continue\n",
    "\n",
    "        # Create local path for blob\n",
    "        local_path = os.path.join(destination_dir, relative_path)\n",
    "        local_path = local_path.replace(\"/\",\"\\\\\")\n",
    "        # Create necessary local directories\n",
    "        os.makedirs(os.path.dirname(local_path), exist_ok=True)\n",
    "\n",
    "        # Download the blob to the local path\n",
    "        blob.download_to_filename(local_path)\n",
    "        print(f\"Downloaded {blob.name} to {local_path}\")\n",
    "\n",
    "# Example usage\n",
    "download_bucket_folder(\"easy-cv-bucket\", \"cv_templates/cv_template_1/\", \".\\output\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T11:28:56.828078600Z",
     "start_time": "2023-11-16T11:28:49.399570Z"
    }
   },
   "id": "531655bc85b3823"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "  # client = storage.Client()\n",
    "bucket = client.get_bucket(\"easy-cv-bucket\")\n",
    "\n",
    "  # Get the text document object.\n",
    "blob = bucket.blob('user/Shresht_Shetty/user_professional_information.txt')\n",
    "\n",
    "  # Download the text document.\n",
    "# text = blob.download_as_string().decode(\"utf-8\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T09:51:46.101670Z",
     "start_time": "2023-11-05T09:51:45.951480200Z"
    }
   },
   "id": "45fe6fb560f5a665"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Shresht Shetty (Photo: shresht_photo.jpg)\n",
      "Address: Maroochydore, Sunshine Coast\n",
      "Phone: +61478917105\n",
      "\n",
      "About:\n",
      "\n",
      "Data science enthusiast, a sports person with good problem solving and team building skills keen to assume new responsibilities and challenges:\n",
      "-Collaborated with cross functioning teams in the fields of insurance, finance (credit risk) and marketing to deliver high performing results\n",
      "-Has created automated workflow pipelines to deploy client models through github actions\n",
      "-Worked in fast paced environments to deliver high quality logistics optimization models to one of the largest grocery chains in Australia\n",
      "\n",
      "Core competencies:\n",
      "\n",
      "- Machine learning pipeline and ETL (Extract, Transform, Load).\n",
      "- AI and LLMs.\n",
      "- Mathematical Optimization\n",
      "- Data Analytics and Data Visualisation.\n",
      "- Workflow automation\n",
      "- CI/CD pipelines\n",
      "\n",
      "\n",
      "Languages:\n",
      "\n",
      "-Programming languages: Python (numpy, sklearn, pandas, matplotlib) , R , SQL, JAVA, Tensorflow.\n",
      "-Big data: AWS, Hadoop, Spark, SAS Enterprise Guide, SAS Studio.\n",
      "-Operations research: CPLEX, Gurobi\n",
      "\n",
      "\n",
      "Data Science and Machine Learning:\n",
      "\n",
      "-Skills: Model development & Deployment, Time-series, Image processing, Natural language processing\n",
      "-Tools: Langchain, Flask, Git, Python, Tensorflow, \n",
      "-Softwares: IBM CPLEX, IBM Watson Studio, AWS EC2, AWS ECR, AWS S3\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n",
      "Experience\n",
      "\n",
      "Data Scientist - BlueSky Creations (logo file: bsc.jpg)\n",
      "August 2021 - Present (2 years 3 months)\n",
      "\n",
      "-Built production scale optimzation software for one of Australia's biggest grocery chains to automate their distribution center operations. \n",
      "-Built conversational chatbots for company platform using LLMs and Langchain. \n",
      "-Built Optimization models such as transport routing, workforce optimization, operation theatre block scheduling models for the company platform.\n",
      "-Employed CI/CD pipelines and MLOps to build AI tools at the company.\n",
      "-Implemented automations in deployment using Github actions, collaborated with other team members using git.\n",
      "\n",
      "\n",
      "Research Assistant - The University of Queensland (logo file: uq.jpg)\n",
      "Jan 2020 - Aus 2021 (1 year 8 months)\n",
      "\n",
      "Conducted multiple experiments to study the impact of demographics on insurance fraud. In addition, studied the effect of insurance plan switching on spending. Furthermore, I used supervised machine learning models in python to study the effect of plan switching on expenditure. \n",
      "-Used Principal component analysis to identify fraudulent claims from insurance claims. Identified the top 10% claims had high suspicion levels.\n",
      "-Conducted various hypothesis tests to understand the difference in suspicion levels between different groups of people.\n",
      "-Worked through the data science pipeline that included cleaning data, manipulating data, regression analysis and testing.\n",
      "- Deployed the logistic regression model to study the effect plan switching has on expenditure.\n",
      "\n",
      "\n",
      "Machine Learning Engineer Intern - CRiskCo (logo file: criskco.jpg)\n",
      "Jun 2019 - April 2020 (11 months)\n",
      "\n",
      "Formed supervised machine learning credit risk models using random forest to identify defaulting companies:\n",
      "-Achieved a Recall of 100% and precision of 16.3% in identifying defaulting companies\n",
      "-Worked with cleaning of data and imputation of missing values: \n",
      " Non temporal features: MICE imputation and KNN imputation\n",
      " Temporal features: Kalman smoothing, LOCF imputation\n",
      "-Used machine learning techniques such as undersampling, oversampling, SMOTE sampling to handle the class imbalance.\n",
      "-Calculated Probability of Default (PD) for all companies, which indicates their creditworthiness.\n",
      "\n",
      "\n",
      "Data Officer - UQ Business School (logo file: uq_bs.png)\n",
      "March 2019 - June 2019 (4 months)\n",
      "\n",
      "Collaborated with the marketing team at UQ Business school to improve the data collection and segmentation process for their client, Queensland Treasury Corporation.\n",
      "-Analyzed and streamlined the data collection process for CRM data.\n",
      "-Imputed missing values, standardized the dataset to a single format for ease of use.\n",
      "-Manipulated data in 20+ databases to create a master database to reduce redundancy.\n",
      "-Delivered a technical presentation to the client that identified faults in their data collection system and included suggestions for improvement. The presentation also contained complex visualisations on segmentation of customers for effective e- marketing.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n",
      "Education\n",
      "\n",
      "Masters in Data Science - The University of Queensland (logo file: uq.jpg)\n",
      "2018 - 2020\n",
      "\n",
      "Bachelors in Chemical Engineering - Manipal Institute of Technology (logo file: MU.jpg)\n",
      "2014 - 2018\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n",
      "Licenses & Certifications\n",
      "\n",
      "- Machine Learning Engineering for Production (MLOps) - Coursera - Dec 2021\n",
      "- AWS Solutions Architect Associate - Amazon Web Services - Issued Jan 2021 Expires Jan 2024\n",
      "- Deep learning specialisation - Coursera - Jan 2019\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "with blob.open(\"r\") as f:\n",
    "  print(f.read())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T09:51:47.676308Z",
     "start_time": "2023-11-05T09:51:47.494758900Z"
    }
   },
   "id": "fa572ae82e518b4c"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "ename": "Forbidden",
     "evalue": "403 GET https://storage.googleapis.com/download/storage/v1/b/easy-cv-bucket/o/user%2FShresht_Shetty%2Fuser_professional_information.txt?alt=media: The billing account for the owning project is disabled in state absent: ('Request failed with status code', 403, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.PARTIAL_CONTENT: 206>)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidResponse\u001B[0m                           Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\envs\\ReviewAnalysis\\lib\\site-packages\\google\\cloud\\storage\\blob.py:4329\u001B[0m, in \u001B[0;36mBlob._prep_and_do_download\u001B[1;34m(self, file_obj, client, start, end, raw_download, if_etag_match, if_etag_not_match, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry, command)\u001B[0m\n\u001B[0;32m   4328\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 4329\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_download\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   4330\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtransport\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4331\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfile_obj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4332\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdownload_url\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4333\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4334\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstart\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4335\u001B[0m \u001B[43m        \u001B[49m\u001B[43mend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4336\u001B[0m \u001B[43m        \u001B[49m\u001B[43mraw_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4337\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4338\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchecksum\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchecksum\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4339\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretry\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretry\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4340\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4341\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m resumable_media\u001B[38;5;241m.\u001B[39mInvalidResponse \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ReviewAnalysis\\lib\\site-packages\\google\\cloud\\storage\\blob.py:985\u001B[0m, in \u001B[0;36mBlob._do_download\u001B[1;34m(self, transport, file_obj, download_url, headers, start, end, raw_download, timeout, checksum, retry)\u001B[0m\n\u001B[0;32m    984\u001B[0m download\u001B[38;5;241m.\u001B[39m_retry_strategy \u001B[38;5;241m=\u001B[39m retry_strategy\n\u001B[1;32m--> 985\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mdownload\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconsume\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtransport\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    986\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_extract_headers_from_download(response)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ReviewAnalysis\\lib\\site-packages\\google\\resumable_media\\requests\\download.py:237\u001B[0m, in \u001B[0;36mDownload.consume\u001B[1;34m(self, transport, timeout)\u001B[0m\n\u001B[0;32m    235\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n\u001B[1;32m--> 237\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_request_helpers\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait_and_retry\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    238\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretriable_request\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_status_code\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_retry_strategy\u001B[49m\n\u001B[0;32m    239\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ReviewAnalysis\\lib\\site-packages\\google\\resumable_media\\requests\\_request_helpers.py:155\u001B[0m, in \u001B[0;36mwait_and_retry\u001B[1;34m(func, get_status_code, retry_strategy)\u001B[0m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 155\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    156\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _CONNECTION_ERROR_CLASSES \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ReviewAnalysis\\lib\\site-packages\\google\\resumable_media\\requests\\download.py:219\u001B[0m, in \u001B[0;36mDownload.consume.<locals>.retriable_request\u001B[1;34m()\u001B[0m\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_object_generation \u001B[38;5;241m=\u001B[39m _helpers\u001B[38;5;241m.\u001B[39m_parse_generation_header(\n\u001B[0;32m    216\u001B[0m         result, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_headers\n\u001B[0;32m    217\u001B[0m     )\n\u001B[1;32m--> 219\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_response\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    221\u001B[0m \u001B[38;5;66;03m# With decompressive transcoding, GCS serves back the whole file regardless of the range request,\u001B[39;00m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;66;03m# thus we reset the stream position to the start of the stream.\u001B[39;00m\n\u001B[0;32m    223\u001B[0m \u001B[38;5;66;03m# See: https://cloud.google.com/storage/docs/transcoding#range\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ReviewAnalysis\\lib\\site-packages\\google\\resumable_media\\_download.py:188\u001B[0m, in \u001B[0;36mDownload._process_response\u001B[1;34m(self, response)\u001B[0m\n\u001B[0;32m    187\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_finished \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 188\u001B[0m \u001B[43m_helpers\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequire_status_code\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    189\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_ACCEPTABLE_STATUS_CODES\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_status_code\u001B[49m\n\u001B[0;32m    190\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ReviewAnalysis\\lib\\site-packages\\google\\resumable_media\\_helpers.py:108\u001B[0m, in \u001B[0;36mrequire_status_code\u001B[1;34m(response, status_codes, get_status_code, callback)\u001B[0m\n\u001B[0;32m    107\u001B[0m         callback()\n\u001B[1;32m--> 108\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m common\u001B[38;5;241m.\u001B[39mInvalidResponse(\n\u001B[0;32m    109\u001B[0m         response,\n\u001B[0;32m    110\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRequest failed with status code\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    111\u001B[0m         status_code,\n\u001B[0;32m    112\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected one of\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    113\u001B[0m         \u001B[38;5;241m*\u001B[39mstatus_codes\n\u001B[0;32m    114\u001B[0m     )\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m status_code\n",
      "\u001B[1;31mInvalidResponse\u001B[0m: ('Request failed with status code', 403, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.PARTIAL_CONTENT: 206>)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mForbidden\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[29], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mblob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdownload_as_string\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ReviewAnalysis\\lib\\site-packages\\google\\cloud\\storage\\blob.py:1518\u001B[0m, in \u001B[0;36mBlob.download_as_string\u001B[1;34m(self, client, start, end, raw_download, if_etag_match, if_etag_not_match, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, retry)\u001B[0m\n\u001B[0;32m   1436\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"(Deprecated) Download the contents of this blob as a bytes object.\u001B[39;00m\n\u001B[0;32m   1437\u001B[0m \n\u001B[0;32m   1438\u001B[0m \u001B[38;5;124;03mIf :attr:`user_project` is set on the bucket, bills the API request\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1513\u001B[0m \u001B[38;5;124;03m:raises: :class:`google.cloud.exceptions.NotFound`\u001B[39;00m\n\u001B[0;32m   1514\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1515\u001B[0m warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m   1516\u001B[0m     _DOWNLOAD_AS_STRING_DEPRECATED, \u001B[38;5;167;01mPendingDeprecationWarning\u001B[39;00m, stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m\n\u001B[0;32m   1517\u001B[0m )\n\u001B[1;32m-> 1518\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdownload_as_bytes\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1519\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1520\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstart\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1521\u001B[0m \u001B[43m    \u001B[49m\u001B[43mend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1522\u001B[0m \u001B[43m    \u001B[49m\u001B[43mraw_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mraw_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1523\u001B[0m \u001B[43m    \u001B[49m\u001B[43mif_etag_match\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mif_etag_match\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1524\u001B[0m \u001B[43m    \u001B[49m\u001B[43mif_etag_not_match\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mif_etag_not_match\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1525\u001B[0m \u001B[43m    \u001B[49m\u001B[43mif_generation_match\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mif_generation_match\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1526\u001B[0m \u001B[43m    \u001B[49m\u001B[43mif_generation_not_match\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mif_generation_not_match\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1527\u001B[0m \u001B[43m    \u001B[49m\u001B[43mif_metageneration_match\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mif_metageneration_match\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1528\u001B[0m \u001B[43m    \u001B[49m\u001B[43mif_metageneration_not_match\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mif_metageneration_not_match\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1529\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1530\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretry\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretry\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1531\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ReviewAnalysis\\lib\\site-packages\\google\\cloud\\storage\\blob.py:1403\u001B[0m, in \u001B[0;36mBlob.download_as_bytes\u001B[1;34m(self, client, start, end, raw_download, if_etag_match, if_etag_not_match, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry)\u001B[0m\n\u001B[0;32m   1313\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Download the contents of this blob as a bytes object.\u001B[39;00m\n\u001B[0;32m   1314\u001B[0m \n\u001B[0;32m   1315\u001B[0m \u001B[38;5;124;03mIf :attr:`user_project` is set on the bucket, bills the API request\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1398\u001B[0m \u001B[38;5;124;03m:raises: :class:`google.cloud.exceptions.NotFound`\u001B[39;00m\n\u001B[0;32m   1399\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1401\u001B[0m string_buffer \u001B[38;5;241m=\u001B[39m BytesIO()\n\u001B[1;32m-> 1403\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_prep_and_do_download\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1404\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstring_buffer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1405\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1406\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstart\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1407\u001B[0m \u001B[43m    \u001B[49m\u001B[43mend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1408\u001B[0m \u001B[43m    \u001B[49m\u001B[43mraw_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mraw_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1409\u001B[0m \u001B[43m    \u001B[49m\u001B[43mif_etag_match\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mif_etag_match\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1410\u001B[0m \u001B[43m    \u001B[49m\u001B[43mif_etag_not_match\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mif_etag_not_match\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1411\u001B[0m \u001B[43m    \u001B[49m\u001B[43mif_generation_match\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mif_generation_match\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1412\u001B[0m \u001B[43m    \u001B[49m\u001B[43mif_generation_not_match\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mif_generation_not_match\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1413\u001B[0m \u001B[43m    \u001B[49m\u001B[43mif_metageneration_match\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mif_metageneration_match\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1414\u001B[0m \u001B[43m    \u001B[49m\u001B[43mif_metageneration_not_match\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mif_metageneration_not_match\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1415\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1416\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchecksum\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchecksum\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1417\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretry\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretry\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1418\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1419\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m string_buffer\u001B[38;5;241m.\u001B[39mgetvalue()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ReviewAnalysis\\lib\\site-packages\\google\\cloud\\storage\\blob.py:4342\u001B[0m, in \u001B[0;36mBlob._prep_and_do_download\u001B[1;34m(self, file_obj, client, start, end, raw_download, if_etag_match, if_etag_not_match, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry, command)\u001B[0m\n\u001B[0;32m   4329\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_do_download(\n\u001B[0;32m   4330\u001B[0m         transport,\n\u001B[0;32m   4331\u001B[0m         file_obj,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4339\u001B[0m         retry\u001B[38;5;241m=\u001B[39mretry,\n\u001B[0;32m   4340\u001B[0m     )\n\u001B[0;32m   4341\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m resumable_media\u001B[38;5;241m.\u001B[39mInvalidResponse \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m-> 4342\u001B[0m     \u001B[43m_raise_from_invalid_response\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexc\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ReviewAnalysis\\lib\\site-packages\\google\\cloud\\storage\\blob.py:4778\u001B[0m, in \u001B[0;36m_raise_from_invalid_response\u001B[1;34m(error)\u001B[0m\n\u001B[0;32m   4774\u001B[0m     error_message \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(error)\n\u001B[0;32m   4776\u001B[0m message \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse\u001B[38;5;241m.\u001B[39mrequest\u001B[38;5;241m.\u001B[39mmethod\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse\u001B[38;5;241m.\u001B[39mrequest\u001B[38;5;241m.\u001B[39murl\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00merror_message\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 4778\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mfrom_http_status(response\u001B[38;5;241m.\u001B[39mstatus_code, message, response\u001B[38;5;241m=\u001B[39mresponse)\n",
      "\u001B[1;31mForbidden\u001B[0m: 403 GET https://storage.googleapis.com/download/storage/v1/b/easy-cv-bucket/o/user%2FShresht_Shetty%2Fuser_professional_information.txt?alt=media: The billing account for the owning project is disabled in state absent: ('Request failed with status code', 403, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.PARTIAL_CONTENT: 206>)"
     ]
    }
   ],
   "source": [
    "blob.download_as_string().decode(\"utf-8\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T07:20:36.626984800Z",
     "start_time": "2023-11-05T07:20:36.403018100Z"
    }
   },
   "id": "b84e24f6a04dc279"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2d58660898cae84e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "reviewanalysis",
   "language": "python",
   "display_name": "ReviewAnalysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
